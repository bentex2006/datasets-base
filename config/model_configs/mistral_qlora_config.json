{
    "model_name_or_path": "mistralai/Mistral-7B-v0.1",
    "dataset_name": "your-dataset-name",
    "output_dir": "./results",
    "num_train_epochs": 3,
    "per_device_train_batch_size": 4,
    "gradient_accumulation_steps": 4,
    "learning_rate": 2e-4,
    "max_grad_norm": 0.3,
    "warmup_ratio": 0.03,
    "lr_scheduler_type": "constant",
    "lora_r": 64,
    "lora_alpha": 16,
    "lora_dropout": 0.1,
    "max_seq_length": 2048,
    "load_in_4bit": true,
    "use_peft": true,
    "quantization": {
        "bits": 4,
        "groupsize": 128,
        "double_quant": true
    }
}
